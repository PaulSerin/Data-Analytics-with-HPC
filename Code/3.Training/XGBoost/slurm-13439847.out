slurmstepd: info: Setting TMPDIR to /scratch/13439847. Previous errors about TMPDIR can be discarded
2025-06-12 23:21:59,926 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.120.210.5:38021'
2025-06-12 23:22:16,570 - distributed.worker - INFO -       Start worker at:   tcp://10.120.210.5:33947
2025-06-12 23:22:16,580 - distributed.worker - INFO -          Listening to:   tcp://10.120.210.5:33947
2025-06-12 23:22:16,580 - distributed.worker - INFO -           Worker name:             SLURMCluster-0
2025-06-12 23:22:16,580 - distributed.worker - INFO -          dashboard at:         10.120.210.5:42819
2025-06-12 23:22:16,580 - distributed.worker - INFO - Waiting to connect to:   tcp://10.120.209.3:36575
2025-06-12 23:22:16,580 - distributed.worker - INFO - -------------------------------------------------
2025-06-12 23:22:16,580 - distributed.worker - INFO -               Threads:                         32
2025-06-12 23:22:16,580 - distributed.worker - INFO -                Memory:                  37.25 GiB
2025-06-12 23:22:16,580 - distributed.worker - INFO -       Local Directory: /scratch/13439847/dask-scratch-space/worker-imy5pdm7
2025-06-12 23:22:16,580 - distributed.worker - INFO - -------------------------------------------------
2025-06-12 23:22:16,755 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-06-12 23:22:16,756 - distributed.worker - INFO -         Registered to:   tcp://10.120.209.3:36575
2025-06-12 23:22:16,756 - distributed.worker - INFO - -------------------------------------------------
2025-06-12 23:22:16,756 - distributed.core - INFO - Starting established connection to tcp://10.120.209.3:36575
2025-06-12 23:23:20,683 - distributed.core - INFO - Event loop was unresponsive in Worker for 33.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
[23:23:44] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.
Potential solutions:
- Use a data structure that matches the device ordinal in the booster.
- Set the device for booster before call to inplace_predict.

This warning will only be shown once.

2025-06-12 23:24:25,046 - distributed.sizeof - WARNING - ("Sizeof calculation for object of type 'dict' failed. Defaulting to -1 B",)
slurmstepd: error: *** JOB 13439847 ON a100-53 CANCELLED AT 2025-06-12T23:24:31 ***
2025-06-12 23:24:31,242 - distributed.worker - INFO - Stopping worker at tcp://10.120.210.5:33947. Reason: scheduler-close
